{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aggressive-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import sklearn.model_selection as model_selection\n",
    "import datetime\n",
    "from model import createModel\n",
    "from contextlib import redirect_stdout\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-implement",
   "metadata": {},
   "source": [
    "# The following model and it's predictions should not be considered as  a valid medical advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "horizontal-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"NonDemented\", \"MildDemented\", \"ModerateDemented\", \"VeryMildDemented\"]\n",
    "SIZE = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exact-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    rawdata = []\n",
    "    data = []\n",
    "    dir = \"./data/\"\n",
    "    for category in categories:\n",
    "        path = os.path.join(dir, category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                rawdata = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_data = cv2.resize(rawdata, (SIZE, SIZE))\n",
    "\n",
    "                data.append([new_data, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    random.shuffle(data)\n",
    "\n",
    "    img_data = []\n",
    "    img_labels = []\n",
    "    for features, label in data:\n",
    "        img_data.append(features)\n",
    "        img_labels.append(label)\n",
    "    img_data = np.array(img_data).reshape(-1, SIZE, SIZE, 1)\n",
    "    img_data = img_data / 255.0\n",
    "    img_labels = np.array(img_labels)\n",
    "\n",
    "    return img_data, img_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "killing-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = getData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fuzzy-synthetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desirable-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(data, labels, test_size=0.20)\n",
    "\n",
    "train_data, val_data, train_labels, val_labels = model_selection.train_test_split(train_data, train_labels,\n",
    "                                                                                  test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "controlling-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    " model = keras.Sequential([\n",
    "\n",
    "            keras.Input(shape=train_data.shape[1:]),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation=\"relu\"),\n",
    "\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(4, activation=\"softmax\")\n",
    "\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "revised-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='./model/model.h5', save_best_only=True, monitor='val_loss',\n",
    "                                             mode='min')\n",
    "\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dominican-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "continued-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "statutory-spouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "144/144 [==============================] - 8s 41ms/step - loss: 1.0998 - accuracy: 0.4602 - val_loss: 1.0139 - val_accuracy: 0.4805\n",
      "Epoch 2/10\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 0.9223 - accuracy: 0.5639 - val_loss: 0.8175 - val_accuracy: 0.6172\n",
      "Epoch 3/10\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 0.7825 - accuracy: 0.6453 - val_loss: 0.6765 - val_accuracy: 0.6914\n",
      "Epoch 4/10\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 0.6166 - accuracy: 0.7284 - val_loss: 0.5143 - val_accuracy: 0.7891\n",
      "Epoch 5/10\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 0.4597 - accuracy: 0.8018 - val_loss: 0.4241 - val_accuracy: 0.8379\n",
      "Epoch 6/10\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 0.3703 - accuracy: 0.8480 - val_loss: 0.3468 - val_accuracy: 0.8750\n",
      "Epoch 7/10\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 0.2519 - accuracy: 0.8974 - val_loss: 0.2530 - val_accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 0.1971 - accuracy: 0.9211 - val_loss: 0.1890 - val_accuracy: 0.9395\n",
      "Epoch 9/10\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 0.1440 - accuracy: 0.9446 - val_loss: 0.1668 - val_accuracy: 0.9453\n",
      "Epoch 10/10\n",
      "144/144 [==============================] - 5s 38ms/step - loss: 0.1424 - accuracy: 0.9471 - val_loss: 0.1946 - val_accuracy: 0.9492\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_labels, epochs=10, validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-license",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai]",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
